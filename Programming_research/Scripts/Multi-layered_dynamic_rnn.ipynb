{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, I demonstrate how to create multi-layered RNN using the tensorflow's dynamic_rnn module.\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Technology used: Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset used for this notebook is the Movie-review-Sentiment-Analysis from kaggle\n",
    "link -> https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start with the usual utility cells and then proceed with preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# packages used for processing: \n",
    "import cPickle as pickle # for reading the data\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import numpy as np\n",
    "\n",
    "# for operating system related stuff\n",
    "import os\n",
    "import sys # for memory usage of objects\n",
    "from subprocess import check_output\n",
    "\n",
    "# the boss of frameworks\n",
    "import tensorflow as tf\n",
    "\n",
    "# for dataset building:\n",
    "import collections\n",
    "\n",
    "# to plot the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../Data/\" directory.\n",
    "\n",
    "def exec_command(cmd):\n",
    "    '''\n",
    "        function to execute a shell command and see it's \n",
    "        output in the python console\n",
    "        @params\n",
    "        cmd = the command to be executed along with the arguments\n",
    "              ex: ['ls', '../input']\n",
    "    '''\n",
    "    print(check_output(cmd).decode(\"utf8\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Models\n",
      "Scripts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the structure of the project directory\n",
    "exec_command(['ls', '..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Set the constants for the script '''\n",
    "\n",
    "# various paths of the files\n",
    "data_path = \"../Data/sentiment_analysis_kaggle/\" # the data path\n",
    "\n",
    "data_files = {\n",
    "    \"train\": os.path.join(data_path, \"train.tsv\"),\n",
    "    \"test\": os.path.join(data_path, \"test.tsv\")\n",
    "}\n",
    "\n",
    "base_model_path = '../Models'\n",
    "\n",
    "model_name = 'Sentiment_Analysis_Model_1'\n",
    "\n",
    "tensorboard_log_dir = os.path.join(base_model_path, model_name)\n",
    "\n",
    "model_save_path = tensorboard_log_dir\n",
    "\n",
    "model_save_filename = os.path.join(model_save_path, model_name)\n",
    "\n",
    "plug_and_play_data_file_path = os.path.join(data_path, \"plug_and_play.pickle\")\n",
    "\n",
    "# constants:\n",
    "vocabulary_size = 15000\n",
    "PAD = 0\n",
    "hidden_cell_state_size = 512 # size of the LSTM cell_state\n",
    "embedding_size = 128\n",
    "num_classes = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "no_of_epochs = 3\n",
    "check_point_factor = 2 # save after seeing 500 minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There doesn't seem to be any obvious package to load this tsv file. So, I am writing a \n",
    "# function myself to extract the training data from the train.tsv file\n",
    "\n",
    "def get_train_data(file_path, feed_back = True, feed_back_factor = 100):\n",
    "    '''\n",
    "        function to load the data from the given file_path and generate a proper data_structure for it.\n",
    "        @param\n",
    "        file_path => the path where the file is located\n",
    "        @return => a list of dictionaries of the formatted data\n",
    "    '''\n",
    "    # open the file and start reading it line by line\n",
    "    with open(file_path, \"r\") as data_file:\n",
    "        heading = data_file.readline()\n",
    "        dict_keys = heading.lower().split() # split the heading to generate the keys for the json dicts\n",
    "        \n",
    "        data = [] # initialize the data to an empty list\n",
    "        # parse the remaining lines and convert them to structured dictionaries\n",
    "        count = 1 # for feedback purposes\n",
    "        for line in data_file:\n",
    "            # split the line at '\\t'\n",
    "            vals = line.strip().split(\"\\t\")\n",
    "            element_dict = {} # initialize to empty dictionary\n",
    "            \n",
    "            # now, put the parsed values in the dict\n",
    "            element_dict[dict_keys[0]] = int(vals[0])\n",
    "            element_dict[dict_keys[1]] = int(vals[1])\n",
    "            element_dict[dict_keys[2]] = vals[2]\n",
    "            element_dict[dict_keys[3]] = int(vals[3])\n",
    "            \n",
    "            # append this newly formed dictionary to the data list\n",
    "            data.append(element_dict)\n",
    "            \n",
    "            if(feed_back and count % feed_back_factor == 0):\n",
    "                print \"Currently processing line number: \" + str(count)\n",
    "                print \"data extracted from this line: \" + str(element_dict) + \"\\n\\n\"\n",
    "            \n",
    "            count += 1 # increment the counter\n",
    "            \n",
    "    # return the so created data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = get_train_data(data_files[\"train\"], feed_back=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phrase': 'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
       " 'phraseid': 1,\n",
       " 'sentenceid': 1,\n",
       " 'sentiment': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data examples to train on: 156060\n"
     ]
    }
   ],
   "source": [
    "print \"Total data examples to train on: \" + str(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words in the dataset: 1124157\n"
     ]
    }
   ],
   "source": [
    "# build a list of words for developing a vocabulary:\n",
    "words = []\n",
    "for elem in data:\n",
    "    words += elem[\"phrase\"].lower().split()\n",
    "    \n",
    "print \"total words in the dataset: \" + str(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in the dataset: 16531\n"
     ]
    }
   ],
   "source": [
    "unique_words = list(set(words))\n",
    "print \"Unique words in the dataset: \" + str(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the dataset: <br>\n",
    "using the helper from https://github.com/akanimax/machine-learning-helpers/blob/master/text/create_vocabulary_for_text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections # only dependency for this function\n",
    "\n",
    "'''\n",
    "    Note: this function assumes the input as a list of words in a meaningful sequence. This function can be easily modified for handling list of sequences as input for special cases of seq2seq models.\n",
    "'''\n",
    "\n",
    "def build_vocabulary(words, n_words):\n",
    "    \"\"\"\n",
    "        Process raw inputs into a dataset.\n",
    "        @param\n",
    "        words => the list of all the words in the dataset\n",
    "        @return => word_count, words_dictionary, words_reverse_dictionary\n",
    "    \"\"\"\n",
    "    count = [['BNK', 0], ['UNK', -1]] # start with this list.\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1)) # this is inplace. i.e. has a side effect\n",
    "\n",
    "    dictionary = dict() # initialize the dictionary to empty one\n",
    "    # fill this dictionary with the most frequent words\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "  \n",
    "    # construct the reverse dictionary for the original dictionary\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "\n",
    "    # return all the relevant stuff\t\n",
    "    return count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain the count, dictionary and the reverse_dictionary for the given dataset. \n",
    "count, dictionary, reverse_dictionary = build_vocabulary(words, vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, use the vocabulary to transform the data into sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dicts(in_dicts, dictionary):\n",
    "    '''\n",
    "        Function to transform the input lists of words into numerical sequences using the dictionary\n",
    "        @param\n",
    "        in_dicts => the list of input data dictionaries\n",
    "        dictionary => the word mapping from every word to an integer\n",
    "        @return => input_sequences, sentiment class of those sequences\n",
    "    '''\n",
    "    input_sequences = []; labels = [] # initialize them to empty ones\n",
    "    \n",
    "    # iterate over every data element dictionary in the data\n",
    "    for elem_dict in data:\n",
    "        seq = elem_dict[\"phrase\"].lower().split()\n",
    "        label = elem_dict[\"sentiment\"]\n",
    "        \n",
    "        # transform the seq using the dictionary\n",
    "        seq = map(lambda x: dictionary[x] if x in dictionary else dictionary['UNK'], seq)\n",
    "        \n",
    "        # print for debugging purposes\n",
    "        # print \"Mapped Sequence: \" + str(seq)\n",
    "        \n",
    "        input_sequences.append(seq); labels.append(label)\n",
    "        \n",
    "    # return the so formed input_sequences and the labels\n",
    "    return input_sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequences, sentiment_labels = transform_dicts(data, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 156060)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(input_sequences) == len(sentiment_labels), \"Data has been corrupted. Seqs and labels length not equal\"\n",
    "len(input_sequences), len(sentiment_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, We have to only once shuffle and save that data permanently, so that the distributions of the train, test and dev set don't change\n",
    "\n",
    "I have done this process and saved the data in the plug_and_play.pickle file. Simply load that file to get the shuffled and split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the function from the helpers repo to pickle the data:\n",
    "\n",
    "link to function -> https://github.com/akanimax/machine-learning-helpers/blob/master/pickling_unpickling/pickling_operations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to unpickle the given file and load the obj back into the python environment\n",
    "def unPickleIt(pickle_path): # might throw the file not found exception\n",
    "    '''\n",
    "        function to unpickle the object from the given path\n",
    "        @param\n",
    "        pickle_path => the path where the pickle file is located\n",
    "        @return => the object extracted from the saved path\n",
    "    '''\n",
    "\n",
    "    with open(pickle_path, 'rb') as dumped_pickle:\n",
    "        obj = pickle.load(dumped_pickle)\n",
    "\n",
    "    return obj # return the unpickled object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = unPickleIt(plug_and_play_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = data_dict['train_X']\n",
    "train_Y = data_dict['train_Y']\n",
    "test_X = data_dict['test_X']\n",
    "test_Y = data_dict['test_Y']\n",
    "labels = data_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative',\n",
       " 1: 'somewhat negative',\n",
       " 2: 'neutral',\n",
       " 3: 'somewhat positive',\n",
       " 4: 'positive'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a function to pad the batch of sequences into a fixed length (by padding) numpy array\n",
    "def pad(seqs):\n",
    "    '''\n",
    "        function to convert the list of seqs into a batch tensor (padding the batch to a nice length)\n",
    "        @param\n",
    "        seqs => the list of variable length scalar sequences\n",
    "        @return => The batch tensor converted using the seqs\n",
    "    '''\n",
    "    \n",
    "    lengths = map(lambda x: len(x), seqs) # extract the lengths of all the sequences in the batch\n",
    "    max_length = max(lengths) # calculate the max of those lengths\n",
    "    \n",
    "    converted_seqs = [] # initialize it to empty list\n",
    "    # for every sequence, pad it upto the length of max_length\n",
    "    for seq in seqs: \n",
    "        while(len(seq) != max_length):\n",
    "            seq = seq + [PAD]\n",
    "        # now append this list to the converted_seqs\n",
    "        converted_seqs.append(seq)\n",
    "        \n",
    "    # return the numpy array corredponding to the converted_seqs\n",
    "    return np.array(converted_seqs).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# So, now the setup is done. Let's move on to the actual dynamic_rnn_building\n",
    "## I will use the InteractiveSession() to work with this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything down below goes wrong, try executing from this reset point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create placeholders for input_sequences and input_labels\n",
    "with tf.variable_scope(\"Inputs\"):\n",
    "    tf_input_seqs = tf.placeholder(tf.int32, shape=(None, None), name='input_sequences')\n",
    "    tf_senti_labs = tf.placeholder(tf.int32, shape=(None), name='sentiment_labels')\n",
    "    one_hot_encoded_senti_labs = tf.one_hot(tf_senti_labs, depth=num_classes, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Embedding\"):\n",
    "    embedding_matrix = tf.get_variable(\"embedding_matrix\", \n",
    "                                shape=(vocabulary_size, embedding_size), initializer=tf.random_uniform_initializer())\n",
    "\n",
    "    # obtain the embedded version of input\n",
    "    embedded_tf_input_seqs = tf.nn.embedding_lookup(embedding_matrix, tf_input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Embedding/embedding_lookup:0' shape=(?, ?, 128) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_tf_input_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single layer of dynamic_rnn:\n",
    "with tf.variable_scope(\"RNN_layer_1\"):\n",
    "    lay1_outputs, lay1_states = tf.nn.dynamic_rnn (\n",
    "                                    tf.nn.rnn_cell.LSTMCell(hidden_cell_state_size, use_peepholes = True),\n",
    "                                    embedded_tf_input_seqs,\n",
    "                                    time_major = True, # the batch size is along the columns\n",
    "                                    dtype = tf.float32 # we have to specify this since there is no initial state\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'RNN_layer_1/rnn/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 512) dtype=float32>, LSTMStateTuple(c=<tf.Tensor 'RNN_layer_1/rnn/while/Exit_2:0' shape=(?, 512) dtype=float32>, h=<tf.Tensor 'RNN_layer_1/rnn/while/Exit_3:0' shape=(?, 512) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "# print the tensor information of lay1_outputs and lay1_states\n",
    "print (lay1_outputs, lay1_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to build the second layer of the dynamic_rnn:\n",
    "# for using a different LSTM cell for this layer, the variable scope of this layer needs to be different \n",
    "# from the earlier layer\n",
    "with tf.variable_scope(\"RNN_layer_2\"):\n",
    "    lay2_outputs, lay2_states = tf.nn.dynamic_rnn (\n",
    "                                    tf.nn.rnn_cell.LSTMCell(hidden_cell_state_size, use_peepholes=True),\n",
    "                                    lay1_outputs, # output of the previous layer is input to this layer\n",
    "                                    time_major = True,\n",
    "                                    initial_state = lay1_states\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'RNN_layer_2/rnn/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 512) dtype=float32>, LSTMStateTuple(c=<tf.Tensor 'RNN_layer_2/rnn/while/Exit_2:0' shape=(?, 512) dtype=float32>, h=<tf.Tensor 'RNN_layer_2/rnn/while/Exit_3:0' shape=(?, 512) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "print (lay2_outputs, lay2_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to build the last layer of the dynamic lstm network\n",
    "with tf.variable_scope(\"RNN_layer3\"):\n",
    "    _, lay3_states = tf.nn.dynamic_rnn (\n",
    "                        tf.nn.rnn_cell.LSTMCell(hidden_cell_state_size, use_peepholes=True),\n",
    "                        lay2_outputs, # output of the previous layer is again the input of this layer\n",
    "                        time_major = True,\n",
    "                        initial_state = lay2_states\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"RNN_layer3/rnn/while/Exit_3:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Now, check what the last layers output state is:\n",
    "pre_projected_logits = lay3_states.h\n",
    "print pre_projected_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will have to project this in order to obtain the logits from the lay3_states.h tensor\n",
    "with tf.variable_scope(\"Final_projection\"):\n",
    "    parameters = {\n",
    "        'weights': tf.get_variable('Final_weights', shape=(hidden_cell_state_size, num_classes), \n",
    "                                   initializer=tf.random_normal_initializer()),\n",
    "        'biases' : tf.get_variable('Final_biases', shape=(1, num_classes), initializer=tf.zeros_initializer())\n",
    "    }\n",
    "\n",
    "    # obtain the last layer activations:\n",
    "    projected_logits = tf.matmul(pre_projected_logits, parameters['weights']) + parameters['biases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Final_projection/add:0' shape=(?, 5) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Loss\"):\n",
    "    # calculate the loss between the projected_logits and the one_hot encoded logits\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=projected_logits, \n",
    "                                                                    labels=one_hot_encoded_senti_labs))\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "with tf.variable_scope(\"Trainer\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the predictions\n",
    "with tf.variable_scope(\"Predictions\"):\n",
    "    # manually take the softmax of the projected logits to obtain the predictions:\n",
    "    predictions = tf.nn.softmax(projected_logits) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errands Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the init op\n",
    "with tf.variable_scope(\"INIT\"):\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the merged summaries op\n",
    "with tf.variable_scope(\"ALL_SUMMARIES\"):\n",
    "    all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualize this graph in Tensorboard to make sure everything is properly wired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the init op\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the tensorboard_visualizer:\n",
    "tensorboard_wirter = tf.summary.FileWriter(logdir=tensorboard_log_dir, graph=sess.graph, filename_suffix='.bot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The graph looks cool! lets move forward with the actual training of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_examples = len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create minibatches of the train_X and train_Y\n",
    "minibatches = [] # initialize to empty list\n",
    "index = 0 # initialize to zero\n",
    "for _ in range(int(np.ceil(float(total_train_examples) / batch_size))):\n",
    "    start = index; end = start + batch_size\n",
    "    mini_batch = (train_X[start: end], train_Y[start: end])\n",
    "    \n",
    "    # add the minibatch to the minibatches\n",
    "    minibatches.append(mini_batch)\n",
    "    \n",
    "    # update the index \n",
    "    index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 33, 64, 64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(minibatches[-1][0]), len(minibatches[-1][1]), len(minibatches[-2][0]), len(minibatches[-2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently doing: epoch 1\n",
      "=======================================================================================================\n",
      "2.) Current Loss: 22.7918\n",
      "4.) Current Loss: 11.7678\n",
      "6.) Current Loss: 4.61158\n",
      "8.) Current Loss: 4.82146\n",
      "10.) Current Loss: 1.6809\n",
      "12.) Current Loss: 2.65704\n",
      "14.) Current Loss: 2.6665\n",
      "16.) Current Loss: 1.73891\n",
      "18.) Current Loss: 1.80513\n",
      "20.) Current Loss: 1.68673\n",
      "22.) Current Loss: 1.45863\n",
      "24.) Current Loss: 1.39958\n",
      "26.) Current Loss: 1.47218\n",
      "28.) Current Loss: 1.53066\n",
      "30.) Current Loss: 1.24003\n",
      "32.) Current Loss: 1.35464\n",
      "34.) Current Loss: 1.53404\n",
      "36.) Current Loss: 1.32031\n",
      "38.) Current Loss: 1.3367\n",
      "40.) Current Loss: 1.46536\n",
      "42.) Current Loss: 1.38062\n",
      "44.) Current Loss: 1.29986\n",
      "46.) Current Loss: 1.30489\n",
      "48.) Current Loss: 1.18321\n",
      "50.) Current Loss: 1.11161\n",
      "52.) Current Loss: 1.39637\n",
      "54.) Current Loss: 1.20431\n",
      "56.) Current Loss: 1.11043\n",
      "58.) Current Loss: 1.3613\n",
      "60.) Current Loss: 1.12724\n",
      "62.) Current Loss: 1.28499\n",
      "64.) Current Loss: 1.20053\n",
      "66.) Current Loss: 1.18349\n",
      "68.) Current Loss: 1.35467\n",
      "70.) Current Loss: 1.2182\n",
      "72.) Current Loss: 1.24563\n",
      "74.) Current Loss: 1.32781\n",
      "76.) Current Loss: 1.38454\n",
      "78.) Current Loss: 1.251\n",
      "80.) Current Loss: 1.34132\n",
      "82.) Current Loss: 1.32353\n",
      "84.) Current Loss: 1.24224\n",
      "86.) Current Loss: 1.20459\n",
      "88.) Current Loss: 1.07332\n",
      "90.) Current Loss: 1.53578\n",
      "92.) Current Loss: 1.18804\n",
      "94.) Current Loss: 1.41634\n",
      "96.) Current Loss: 1.30298\n",
      "98.) Current Loss: 1.28094\n",
      "100.) Current Loss: 1.26405\n",
      "102.) Current Loss: 1.16534\n",
      "104.) Current Loss: 1.22579\n",
      "106.) Current Loss: 1.13629\n",
      "108.) Current Loss: 1.26271\n",
      "110.) Current Loss: 1.23381\n",
      "112.) Current Loss: 1.07327\n",
      "114.) Current Loss: 1.15868\n",
      "116.) Current Loss: 1.45154\n",
      "118.) Current Loss: 1.21212\n",
      "120.) Current Loss: 1.17709\n",
      "122.) Current Loss: 1.12384\n",
      "124.) Current Loss: 1.22527\n",
      "126.) Current Loss: 1.18789\n",
      "128.) Current Loss: 1.17904\n",
      "130.) Current Loss: 1.45251\n",
      "132.) Current Loss: 1.33113\n",
      "134.) Current Loss: 1.18973\n",
      "136.) Current Loss: 1.40579\n",
      "138.) Current Loss: 1.25987\n",
      "140.) Current Loss: 1.3164\n",
      "142.) Current Loss: 1.13728\n",
      "144.) Current Loss: 1.29745\n",
      "146.) Current Loss: 1.36733\n",
      "148.) Current Loss: 1.35475\n",
      "150.) Current Loss: 1.39027\n",
      "152.) Current Loss: 1.23755\n",
      "154.) Current Loss: 1.12735\n",
      "156.) Current Loss: 1.16588\n",
      "158.) Current Loss: 1.29684\n",
      "160.) Current Loss: 1.39674\n",
      "162.) Current Loss: 1.14457\n",
      "164.) Current Loss: 1.2809\n",
      "166.) Current Loss: 1.07247\n",
      "168.) Current Loss: 1.22317\n",
      "170.) Current Loss: 1.31274\n",
      "172.) Current Loss: 1.15016\n",
      "174.) Current Loss: 1.25899\n",
      "176.) Current Loss: 1.11908\n",
      "178.) Current Loss: 1.19855\n",
      "180.) Current Loss: 1.1641\n",
      "182.) Current Loss: 1.22379\n",
      "184.) Current Loss: 1.25552\n",
      "186.) Current Loss: 1.09189\n",
      "188.) Current Loss: 1.14695\n",
      "190.) Current Loss: 1.34224\n",
      "192.) Current Loss: 1.19545\n",
      "194.) Current Loss: 1.26431\n",
      "196.) Current Loss: 1.33227\n",
      "198.) Current Loss: 1.21405\n",
      "200.) Current Loss: 1.3743\n",
      "202.) Current Loss: 1.21737\n",
      "204.) Current Loss: 1.36838\n",
      "206.) Current Loss: 1.34956\n",
      "208.) Current Loss: 1.24129\n",
      "210.) Current Loss: 1.31834\n",
      "212.) Current Loss: 1.08804\n",
      "214.) Current Loss: 1.32423\n",
      "216.) Current Loss: 1.15496\n",
      "218.) Current Loss: 1.30235\n",
      "220.) Current Loss: 1.23156\n",
      "222.) Current Loss: 1.22096\n",
      "224.) Current Loss: 1.28116\n",
      "226.) Current Loss: 1.29813\n",
      "228.) Current Loss: 1.25484\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "\n",
    "# start the training iterations\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Currently doing: epoch \" + str(epoch + 1)\n",
    "    print \"=======================================================================================================\"\n",
    "    \n",
    "    # iterate over every minibatch\n",
    "    for iteration in range(len(minibatches)):\n",
    "        (mini_train_X, mini_train_Y) = minibatches[iteration]\n",
    "        \n",
    "        # compute the train_step.\n",
    "        sess.run(train_step, feed_dict={tf_input_seqs: pad(mini_train_X), tf_senti_labs: mini_train_Y})\n",
    "        \n",
    "        # if it is checkpoint factor:\n",
    "        if((iteration + 1) % check_point_factor == 0):\n",
    "            # compute the cost and the summary for cost\n",
    "            summaries, cost = sess.run((all_summaries, loss), feed_dict={tf_input_seqs: pad(mini_train_X), tf_senti_labs: mini_train_Y})\n",
    "            \n",
    "            # print a small message for feedback\n",
    "            print str(iteration + 1) + \".) Current Loss: \" + str(cost)\n",
    "            \n",
    "            # add the summary\n",
    "            tensorboard_wirter.add_summary(summaries, global_step=(iteration + 1))\n",
    "    \n",
    "    print \"=======================================================================================================\\n\\n\"\n",
    "    \n",
    "    # save the model after every epoch\n",
    "    saver.save(sess, model_save_filename, global_step=(epoch + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
